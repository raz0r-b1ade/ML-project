{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exploratory Data Analysis of YallaMotors Cars Dataset\n",
    "\n",
    "This notebook performs exploratory data analysis on the YallaMotors Cars Dataset. The dataset contains information about various cars, including their specifications, prices, and other relevant features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import re\n",
    "import pandas as pd\n",
    "import opendatasets as od"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# About this file\n",
    "\n",
    "This dataset was scraped from the YallaMotors website using Python and Requests-HTML. It consists of approximately 6750 rows and 9 columns, making it suitable for conducting Exploratory Data Analysis and applying Machine Learning algorithms such as Linear Regression and so on.\n",
    "\n",
    "The dataset contains the following columns:\n",
    "* Car Name: The name of the car.\n",
    "* Price: The price of the car.\n",
    "* Engine Capacity: The engine capacity of the car.\n",
    "* Cylinder: The power of the car's cylinder.\n",
    "* Horse Power: The horse power of the car.\n",
    "* Top Speed: The top speed of the car.\n",
    "* Seats: The number of seats in the car.\n",
    "* Brand: The brand of the car.\n",
    "* Country: The country in which the website sells this car.\n",
    "\n",
    "With this dataset, you can explore various aspects of the cars, analyze their features, and perform tasks like predicting the car price using machine learning algorithms.\n",
    "This dataset provides a valuable resource for conducting detailed analysis and gaining insights into the car market."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# download the dataset (this is a Kaggle dataset)\n",
    "# during download you will be required to input your Kaggle username and password\n",
    "od.download(\"https://www.kaggle.com/datasets/mahmoudahmed6/yallamotors-cars-dataset\", force=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After reading the CSV file and loading it into a DataFrame, let's explore the dataset to gain initial insights into the data.\n",
    "\n",
    "The dataset consists of cars with various attributes, including the car name, price, engine capacity, cylinder power, horse power, top speed, number of seats, brand, and country. It contains around 6,308 rows, each representing a car entry.\n",
    "\n",
    "Let's take a look at the first few and last rows of the dataset:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame and display it\n",
    "df = pd.read_csv('./yallamotors-cars-dataset/cars.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Information\n",
    "To gain a deeper understanding of the dataset, let's examine its information using the info() method. This will provide us with essential details about the DataFrame, including the column names, data types, and the number of non-null values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display information about the DataFrame\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the information provided, we can observe the following:\n",
    "\n",
    "* The dataset contains 6,308 entries (rows) and 9 columns.\n",
    "* The column \"Price\" is currently stored as an object (string) type, which may contain a combination of text and numbers.\n",
    "* The \"Engine Capacity\", \"Cylinder\", \"Horse Power\", \"Top Speed\", and \"Seats\" columns are also stored as object types, even though they should ideally be numerical.\n",
    "* There are some missing values in the \"Engine Capacity\", \"Cylinder\", \"Horse Power\", and \"Top Speed\" columns, as indicated by the non-null counts.\n",
    "* The \"Engine Capacity\" and \"Top Speed\" columns have float64 data types, indicating that they already contain numerical values.\n",
    "\n",
    "This initial data overview highlights some data quality issues and potential areas for data cleaning and preprocessing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data wrangling and basic feature engineering\n",
    "\n",
    "To enhance the analysis and enable comparisons, we can convert the prices from various currencies to USD. The code provided performs the following steps:\n",
    "\n",
    "* A dictionary, currency_rates, is defined to store the conversion rates from different currencies to USD.\n",
    "* Two functions, extract_currency(price) and extract_price(price), are defined to extract the currency and price value from the original \"Price\" column, respectively.\n",
    "* The function convert_to_usd(price, currency) converts the extracted price to USD based on the provided currency and conversion rate from the currency_rates dictionary.\n",
    "* Three new columns are created in the DataFrame:\n",
    "* \"currency\" stores the extracted currency values.\n",
    "* \"price_currency\" contains the extracted price values.\n",
    "* \"price_USD\" holds the converted price values in USD.\n",
    "\n",
    "To facilitate further analysis and eliminate redundancy, we can drop the initial \"Price\" column from the DataFrame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To further prepare the dataset for exploratory analysis, the code provided includes the following steps:\n",
    "\n",
    "* The function extract_seats(value) is defined to extract the number of seats from the \"seats\" column. It searches for a pattern that matches a number followed by the word \"seater\" (e.g., \"8 seater\"). If a match is found, the function returns the extracted number as an integer. Otherwise, it returns None.\n",
    "* The function is applied to the \"seats\" column using the apply method, and the results are stored in a new column called \"seats\".\n",
    "* The columns 'engine_capacity', 'cylinder', 'horse_power', and 'top_speed' are converted to numeric format using the pd.to_numeric function. The errors='coerce' parameter is used to handle any non-numeric values by converting them to NaN (Not a Number).\n",
    "* The info() method is then called to display information about the DataFrame, including the data types and the number of non-null values in each column.\n",
    "\n",
    "After performing these conversions, we can ensure that the numeric columns are in the correct format for further analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define currency conversion rates to USD\n",
    "currency_rates = {\n",
    "    'AED': 0.27,   # UAE Dirham\n",
    "    'BHD': 2.65,   # Bahraini Dinar\n",
    "    'EGP': 0.064,  # Egyptian Pound\n",
    "    'KWD': 3.32,   # Kuwaiti Dinar\n",
    "    'OMR': 2.60,   # Omani Rial\n",
    "    'QAR': 0.27,   # Qatari Rial\n",
    "    'SAR': 0.27    # Saudi Rial\n",
    "}\n",
    "\n",
    "# Function to extract currency from price\n",
    "def extract_currency(price):\n",
    "    match = re.search(r'([a-zA-Z]{3})', price)\n",
    "    if match:\n",
    "        currency = match.group(1)\n",
    "        if currency in currency_rates:\n",
    "            return currency\n",
    "    return\n",
    "\n",
    "# Function to extract price from price\n",
    "def extract_price(price):\n",
    "    match = re.search(r'\\d+(,\\d+)?', price)\n",
    "    if match:\n",
    "        return float(match.group(0).replace(',', ''))\n",
    "    return\n",
    "\n",
    "# Function to convert price to USD\n",
    "def convert_to_usd(price, currency):\n",
    "    if currency and currency != 'USD' and currency in currency_rates:\n",
    "        conversion_rate = currency_rates[currency]\n",
    "        return round(price * conversion_rate, 2)\n",
    "    return\n",
    "\n",
    "# Create new columns for currency and price\n",
    "df['currency'] = df['price'].apply(extract_currency)\n",
    "df['price_currency'] = df['price'].apply(extract_price)\n",
    "\n",
    "# Convert price to USD\n",
    "df['price_USD'] = df.apply(lambda row: convert_to_usd(row['price_currency'], row['currency']), axis=1)\n",
    "\n",
    "# Function to extract the number of seats\n",
    "def extract_seats(value):\n",
    "    if isinstance(value, str):\n",
    "        match = re.search(r'\\b(\\d+)\\s*seater\\b', value, re.IGNORECASE)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "# Apply the function to the \"seats\" column\n",
    "df['seats'] = df['seats'].apply(extract_seats)\n",
    "\n",
    "# Convert 'engine_capacity' column to numeric\n",
    "df['engine_capacity'] = pd.to_numeric(df['engine_capacity'], errors='coerce')\n",
    "\n",
    "# Convert 'cylinder' column to numeric (assuming missing values should be NaN)\n",
    "df['cylinder'] = pd.to_numeric(df['cylinder'], errors='coerce')\n",
    "\n",
    "# Convert 'horse_power' column to numeric\n",
    "df['horse_power'] = pd.to_numeric(df['horse_power'], errors='coerce')\n",
    "\n",
    "# Convert 'top_speed' column to numeric\n",
    "df['top_speed'] = pd.to_numeric(df['top_speed'], errors='coerce')\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The current DataFrame information shows that after the data conversions and cleaning steps, the dataset contains 6308 rows and 12 columns. Here is a summary of the columns and their respective non-null counts and data types.\n",
    "Upon examining the DataFrame, we can observe the following information:\n",
    "\n",
    "* The column 'car name' contains 6308 non-null values, indicating that all rows have a car name entry.\n",
    "* The column 'price' also contains 6308 non-null values, indicating that all rows have a price entry.\n",
    "* The column 'engine_capacity' has 6305 non-null values, implying that there are three missing values in this column.\n",
    "* The column 'cylinder' has 5574 non-null values, suggesting that there are 734 missing values in this column.\n",
    "* The column 'horse_power' has 6186 non-null values, indicating that there are 122 missing values in this column.\n",
    "* The column 'top_speed' has 5875 non-null values, implying that there are 433 missing values in this column.\n",
    "* The column 'seats' has 5789 non-null values, indicating that there are 519 missing values in this column.\n",
    "* The columns 'brand' and 'country' contain 6308 non-null values, indicating that there are no missing values in these columns.\n",
    "* The columns 'currency', 'price_currency', and 'price_USD' have missing values, with 4979 non-null values in each column.\n",
    "\n",
    "This information provides an overview of the missing values present in the DataFrame, which can be further analyzed and addressed in the data exploration and cleaning process."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check the number of missing values in each column\n",
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To deal with missing data, we have several options:\n",
    "\n",
    "1. Dropping data:\n",
    "\n",
    "* Dropping the whole row: This method involves removing rows that contain missing values. It can be applied when the missing values are limited to a few rows and do not significantly impact the overall dataset. In our case, we can choose to drop specific rows if they have missing values in crucial columns.\n",
    "* Dropping the whole column: This method involves removing columns that have a significant number of missing values. It is suitable when a column has a large proportion of missing values and does not provide valuable information. However, in our dataset, none of the columns have a high number of missing values, so dropping entire columns is not necessary.\n",
    "\n",
    "2. Replacing data:\n",
    "\n",
    "* Replacing missing values with the mean:\n",
    "\n",
    "    This method involves replacing missing values with the mean value of the respective column. It can be applied to numeric columns where the mean value is a reasonable estimate. In our code, we haven't used this method.\n",
    "\n",
    "* Replacing missing values with the frequency: This method involves replacing missing values with the most frequent value in the respective column. It can be applied to categorical columns where the most frequent value represents a reasonable estimate. In our code, we haven't used this method.\n",
    "\n",
    "* Replacing missing values based on other functions:\n",
    "\n",
    "    This method involves replacing missing values using other techniques, such as interpolation, regression models, or domain-specific knowledge. The choice of replacement method depends on the specific context and the characteristics of the data. In our code, we'll use this method later."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We performed the following actions:\n",
    "\n",
    "* Drop the column \"price\":\n",
    "\n",
    "Since we have already converted the price to separate columns for currency and USD, the original \"price\" column becomes redundant. We dropped it using the drop() function with axis=1 to indicate a column-wise operation.\n",
    "\n",
    "* Drop rows with missing values:\n",
    "\n",
    "We dropped rows with missing values in the \"price_USD\" column because those rows do not provide useful information for our analysis.\n",
    "We also dropped rows with missing values in the \"seats\", \"engine_capacity\", \"cylinder\", \"horse_power\", and \"top_speed\" columns. Since these are critical characteristics of the cars and we cannot reasonably estimate or replace missing values for them, it is more appropriate to remove the rows with missing data.\n",
    "\n",
    "After performing these actions, we checked for missing values again using isnull().sum(). The output would show the number of missing values in each column. Since all the columns in the output have zero missing values, it indicates that we have successfully dropped the rows with missing data.\n",
    "\n",
    "The rationale behind these actions is as follows:\n",
    "\n",
    "* The \"price\" column becomes redundant after extracting the separate columns for currency and USD.\n",
    "* Rows without price in USD are not useful for our analysis, so we can safely drop them.\n",
    "* The remaining numeric characteristics (seats, engine capacity, cylinder, horse power, top speed) are essential attributes of the cars, and since we cannot reliably estimate or replace missing values for them, it is more appropriate to drop the rows with missing data.\n",
    "\n",
    "By dropping the irrelevant column and the rows with missing values, we ensure that our dataset contains only relevant and complete information for further analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Drop the column \"price\" from the DataFrame\n",
    "df.drop(\"price\", axis=1, inplace=True)\n",
    "\n",
    "# Drop rows with missing values in the \"price_USD\" column\n",
    "df.dropna(subset=['price_USD'], inplace=True)\n",
    "\n",
    "# Drop rows with missing values in the \"seats\" column\n",
    "df.dropna(subset=['seats'], inplace=True)\n",
    "\n",
    "# Drop rows with missing values in the \"engine_capacity\" column\n",
    "df.dropna(subset=['engine_capacity'], inplace=True)\n",
    "\n",
    "# Drop rows with missing values in the \"cylinder\" column\n",
    "df.dropna(subset=['cylinder'], inplace=True)\n",
    "\n",
    "# Drop rows with missing values in the \"horse_power\" column\n",
    "df.dropna(subset=['horse_power'], inplace=True)\n",
    "\n",
    "# Drop rows with missing values in the \"top_speed\" column\n",
    "df.dropna(subset=['top_speed'], inplace=True)\n",
    "\n",
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* The \"count\" values for all columns indicate that there are 4096 non-null entries, suggesting that the previous data cleaning steps successfully removed rows with missing values.\n",
    "\n",
    "* The \"mean\" values provide an estimate of the central tendency of the data. For example, the average engine capacity is around 5.32, the average number of cylinders is approximately 281.43, and the average horsepower is about 221.74.\n",
    "\n",
    "* The \"std\" values represent the standard deviation, which measures the spread or dispersion of the data around the mean. Higher standard deviation values indicate greater variability in the data. For instance, the column with the highest variability appears to be \"seats\" with a standard deviation of approximately 185,915.34.\n",
    "\n",
    "* The \"min\" values represent the lowest values observed in each column, while the \"max\" values indicate the highest values. For example, the minimum engine capacity is 3.0, and the maximum is 16.0.\n",
    "\n",
    "* The \"25%\", \"50%\", and \"75%\" percentiles provide information about the distribution of the data. The 25th percentile (Q1) indicates the value below which 25% of the data falls, the 50th percentile (Q2) represents the median, and the 75th percentile (Q3) indicates the value below which 75% of the data falls. These percentiles help understand the range and distribution of the data.\n",
    "\n",
    "Overall, the descriptive statistics provide insights into the central tendency, variability, and distribution of the numeric columns in the DataFrame. We can further analyze and interpret the statistics to gain a better understanding of the car characteristics and identify any outliers or patterns within the data.\n",
    "Additionally, we can consider visualizing the data using plots and charts to explore relationships and patterns within the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#descriptive statistics of the DataFrame\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After analyzing the initial descriptive statistics using the describe() function, several issues were identified:\n",
    "\n",
    "* Min price in USD: The minimum price in USD was found to be 0, which is not realistic for car prices.\n",
    "\n",
    "* Unreal engine capacity: Some of the engine capacity values were identified to be unrealistic, including extremely high values such as 6000 liters and low values like 0.1 liters (originally 100 milliliters).\n",
    "\n",
    "To address these issues, the following actions were taken:\n",
    "\n",
    "* Price in USD: Rows with a price in USD less than $7000 were filtered out. This helps to remove unrealistic and irrelevant price values.\n",
    "\n",
    "* Engine Capacity: The engine capacity values greater than 100 (originally in milliliters) were updated to represent liters instead.\n",
    "\n",
    "After applying these actions, the DataFrame has been updated to ensure more accurate and meaningful data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Update engine capacity values greater than 100 to represent liters instead of milliliters\n",
    "df.loc[df['engine_capacity'] > 100, 'engine_capacity'] = (df['engine_capacity'] / 1000).round(1)\n",
    "\n",
    "# Filter the DataFrame to keep rows with engine_capacity greater than or equal to 1\n",
    "df = df.loc[df['engine_capacity'] >= 1]\n",
    "\n",
    "# Filter the DataFrame to keep rows with price_USD greater than or equal to 7000\n",
    "df = df.loc[df['price_USD'] >= 7000]\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Overall, the DataFrame has been refined, and the columns now contain meaningful and cleaned data without missing values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data has undergone several modifications to address missing values, incorrect units, and unrealistic values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After checking for duplicates in the 'car name' column, it appears that there are multiple entries with the same car name. However, upon further analysis, it can be observed that these duplicates correspond to different countries. Each car name is associated with a specific country, and the duplicates arise from having the same car model available in multiple countries.\n",
    "\n",
    "For example, the car model \"Peugeot 5008 2021 1.6T Active\" appears 7 times, but each entry corresponds to a different country. The same pattern is observed for other car models as well.\n",
    "\n",
    "Therefore, having duplicates in the 'car name' column is acceptable in this dataset since the duplicates represent the same car model available in different countries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#check duplicates\n",
    "df[df.duplicated(subset='car name', keep=False)]['car name'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The wrangling is done.\n",
    "The cleaned DataFrame has been saved to the CSV file 'wrangled_cars.csv' without including the index column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file without including the index column\n",
    "df.to_csv('wrangled_cars.csv', index=False)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "\n",
    "We inspected the dataset and found that it had 6,277 rows and 11 columns. We noticed missing values in some columns and decided to drop those rows to ensure data integrity. Afterward, we proceeded with data type conversions to ensure the appropriate data types for each column.\n",
    "\n",
    "During the cleaning process, we identified and handled duplicates in the dataset, specifically focusing on the \"car name\" column. We discovered several cars with the same name but different specifications, likely due to different models or years. Since the quantity of duplicates for each car name did not exceed 7, which corresponds to the number of countries represented in the dataset, we concluded that this duplication was acceptable.\n",
    "\n",
    "Additionally, we performed some basic descriptive statistics on the dataset, providing insights into the distribution and range of values for numeric columns. This allowed us to get a better understanding of the dataset's characteristics.\n",
    "\n",
    "Finally, we saved the cleaned dataset to a CSV file named 'wrangled_cars.csv', excluding the index column to maintain a clean and organized structure.\n",
    "\n",
    "In summary, our work involved cleaning and wrangling the car dataset, which consisted of removing missing values, converting data types, handling duplicates, and performing basic descriptive statistics. The resulting dataset is now ready for further analysis and exploration of various factors related to car specifications, brands, countries, and prices."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
